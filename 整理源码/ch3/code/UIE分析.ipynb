{"cells":[{"cell_type":"markdown","metadata":{"trusted":true,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"D89B0EAB542642F98900CCC4D4E49360","runtime":{"status":"default","execution_status":null,"is_visible":false},"scrolled":false,"notebookId":"681762dad4034699adc59cac"},"source":"\n"},{"cell_type":"code","metadata":{"id":"810CF482643D4985AFA558B9F60AF78D","notebookId":"681762dad4034699adc59cac","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"source":"import os\nimport logging\nimport pandas as pd\nimport numpy as np\nimport json\nimport pickle\nimport signal\nimport time\nimport sys\nfrom pathlib import Path\nfrom concurrent.futures import ProcessPoolExecutor\nfrom paddlenlp import Taskflow\nfrom tqdm import tqdm\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nimport seaborn as sns\nimport jieba\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# —— 配置区 —— \nCSV_PATH    = r\"D:\\CODE_WORLD\\No.15CDR_workspace\\data\\texts\\无人驾驶网约车评论数据.csv\"\nOUTPUT_DIR  = \"D:\\\\CODE_WORLD\\\\No.15CDR_workspace\\\\results\\\\uie_analysis\"\nOUTPUT_FILE_PREFIX = \"autonomous_vehicle_analysis\"\nDEVICE_ID   = 0      # 如果没有GPU，设为None 或删除 device_id\nBATCH_SIZE  = 8\nNUM_WORKERS = 2\n\n# —— 断点续传配置 ——\nCHECKPOINT_DIR = os.path.join(OUTPUT_DIR, \"checkpoints\")\nPROGRESS_FILE = os.path.join(CHECKPOINT_DIR, \"progress.json\")\n# 可以通过键盘中断安全退出的标志\nINTERRUPT_FLAG = False\n\n# —— 我们扩展的\"维度\"（schema）如下 —— \nSCHEMA = [\n    \"主题关键词\",     # 核心话题词，如\"安全\"、\"定价\"等\n    \"情感倾向\",       # 正面/负面/中性\n    \"安全关注\",       # 用户对行程安全的具体评论\n    \"舒适度\",         # 座椅、车内体验等\n    \"价格评价\",       # 价格合理性、优惠诉求\n    \"服务体验\",       # 车辆清洁、接送速度、司机交互\n    \"技术可靠性\",     # 自动驾驶的稳定性、故障抱怨\n    \"法规合规\",       # 对地方政策、法规遵守的关注\n    \"隐私保护\"        # 个人数据或车内监控的担忧\n]\n\n# 定义每个维度的特征词，用于增强提取能力\nFEATURE_WORDS = {\n    \"安全关注\": [\"安全\", \"刹车\", \"紧急\", \"事故\", \"风险\", \"躲避\", \"危险\", \"撞车\", \"路况\", \"应急\"],\n    \"舒适度\": [\"舒适\", \"座椅\", \"空间\", \"噪音\", \"平稳\", \"颠簸\", \"温度\", \"空调\", \"气味\", \"环境\"],\n    \"价格评价\": [\"价格\", \"费用\", \"贵\", \"便宜\", \"经济\", \"优惠\", \"划算\", \"收费\", \"性价比\", \"成本\"],\n    \"服务体验\": [\"服务\", \"态度\", \"等待\", \"准时\", \"接送\", \"卫生\", \"整洁\", \"礼貌\", \"响应\", \"交互\"],\n    \"技术可靠性\": [\"技术\", \"故障\", \"系统\", \"稳定\", \"错误\", \"反应\", \"延迟\", \"精准\", \"导航\", \"识别\"],\n    \"法规合规\": [\"法规\", \"合规\", \"政策\", \"许可\", \"牌照\", \"合法\", \"监管\", \"规定\", \"标准\", \"要求\"],\n    \"隐私保护\": [\"隐私\", \"数据\", \"监控\", \"摄像头\", \"记录\", \"个人信息\", \"追踪\", \"保密\", \"共享\", \"安全\"]\n}\n\nlogging.basicConfig(level=logging.INFO, format=\"%(levelname)s | %(message)s\")\n\n# 设置键盘中断信号处理函数\ndef handle_interrupt(signum, frame):\n    global INTERRUPT_FLAG\n    if not INTERRUPT_FLAG:\n        logging.warning(\"\\n收到中断信号，将在当前批次处理完成后安全退出...\")\n        logging.warning(\"再次按Ctrl+C将强制退出（不推荐）\")\n        INTERRUPT_FLAG = True\n    else:\n        logging.error(\"强制退出！可能会丢失部分数据\")\n        sys.exit(1)\n\n# 注册信号处理函数\nsignal.signal(signal.SIGINT, handle_interrupt)\nsignal.signal(signal.SIGTERM, handle_interrupt)\n\nclass ProgressManager:\n    \"\"\"管理分析进度的类，用于实现断点续传\"\"\"\n    \n    # 定义处理阶段\n    STAGES = [\n        \"load_data\",           # 加载数据\n        \"uie_extraction\",      # UIE信息抽取\n        \"comment_level_data\",  # 评论级别数据处理\n        \"dimension_stats\",     # 维度统计\n        \"topic_document\",      # 主题-文档矩阵\n        \"sentiment_analysis\",  # 情感分析\n        \"keyword_analysis\",    # 关键词分析\n        \"visualization_data\",  # 可视化数据准备\n        \"summary\"              # 生成摘要\n    ]\n    \n    def __init__(self, checkpoint_dir=CHECKPOINT_DIR, progress_file=PROGRESS_FILE):\n        \"\"\"初始化进度管理器\"\"\"\n        self.checkpoint_dir = checkpoint_dir\n        self.progress_file = progress_file\n        self.current_progress = self._load_progress()\n        \n        # 确保checkpoint目录存在\n        os.makedirs(self.checkpoint_dir, exist_ok=True)\n    \n    def _load_progress(self):\n        \"\"\"加载进度信息\"\"\"\n        if os.path.exists(self.progress_file):\n            try:\n                with open(self.progress_file, \"r\", encoding=\"utf-8\") as f:\n                    progress = json.load(f)\n                logging.info(f\"从 {self.progress_file} 加载进度信息\")\n                return progress\n            except Exception as e:\n                logging.warning(f\"加载进度信息失败: {e}\")\n        \n        # 如果没有进度文件或加载失败，初始化一个新的进度\n        return {\n            \"stages\": {stage: False for stage in self.STAGES},\n            \"batch_progress\": {\n                \"total_batches\": 0,\n                \"completed_batches\": 0\n            },\n            \"last_run\": None,\n            \"processed_ids\": []\n        }\n    \n    def save_progress(self):\n        \"\"\"保存当前进度\"\"\"\n        self.current_progress[\"last_run\"] = pd.Timestamp.now().isoformat()\n        with open(self.progress_file, \"w\", encoding=\"utf-8\") as f:\n            json.dump(self.current_progress, f, ensure_ascii=False, indent=2)\n    \n    def is_stage_completed(self, stage):\n        \"\"\"检查指定阶段是否已完成\"\"\"\n        return self.current_progress[\"stages\"].get(stage, False)\n    \n    def mark_stage_complete(self, stage):\n        \"\"\"标记阶段为已完成\"\"\"\n        if stage in self.STAGES:\n            self.current_progress[\"stages\"][stage] = True\n            self.save_progress()\n            logging.info(f\"阶段 [{stage}] 已完成并保存进度\")\n    \n    def update_batch_progress(self, total_batches, completed_batches):\n        \"\"\"更新批处理进度\"\"\"\n        self.current_progress[\"batch_progress\"] = {\n            \"total_batches\": total_batches,\n            \"completed_batches\": completed_batches\n        }\n        # 每10个批次保存一次进度，避免频繁IO\n        if completed_batches % 10 == 0 or completed_batches == total_batches:\n            self.save_progress()\n    \n    def add_processed_ids(self, ids):\n        \"\"\"添加已处理的评论ID\"\"\"\n        self.current_progress[\"processed_ids\"].extend(ids)\n        \n    def get_processed_ids(self):\n        \"\"\"获取已处理的评论ID列表\"\"\"\n        return set(self.current_progress.get(\"processed_ids\", []))\n    \n    def reset_progress(self, confirm=False):\n        \"\"\"重置进度（需确认）\"\"\"\n        if confirm:\n            self.current_progress = {\n                \"stages\": {stage: False for stage in self.STAGES},\n                \"batch_progress\": {\n                    \"total_batches\": 0,\n                    \"completed_batches\": 0\n                },\n                \"last_run\": None,\n                \"processed_ids\": []\n            }\n            self.save_progress()\n            logging.info(\"进度已重置\")\n        else:\n            logging.warning(\"需要确认才能重置进度\")\n\ndef init_worker(device_id):\n    \"\"\"在每个子进程中初始化 UIE 模型\"\"\"\n    global uie\n    uie = Taskflow(\n        \"information_extraction\",\n        schema=SCHEMA,\n        model=\"uie-mini\",  # 使用更大的模型提升提取效果\n        device_id=device_id,\n        static_mode=True,\n        position_prob=0.4,  # 降低阈值，提高召回率\n        use_fast=True,\n        use_fp16_decoding=True\n    )\n    logging.info(f\"Worker ready on device {device_id}\")\n\ndef process_batch(batch_data):\n    \"\"\"\n    批量处理一组评论：\n    batch_data 是元组 (batch_ids, batch_texts)\n    返回一个 dict: {\n        \"ids\": [...], \n        \"raw\": {...},  # 原始UIE结果\n        \"enhanced\": {...},  # 增强后结果\n        \"by_id\": {}  # 按ID组织的详细结果\n    }\n    \"\"\"\n    batch_ids, batch = batch_data\n    # 原始UIE提取\n    results = uie(batch)\n    \n    # 整合结果\n    merged = {k: [] for k in SCHEMA}\n    result_by_id = {}\n    \n    for i, item in enumerate(results):\n        comment_id = batch_ids[i]\n        result_by_id[comment_id] = {\n            \"text\": batch[i],  # 原始评论文本\n            \"uie_results\": item,  # UIE提取结果\n            \"dimensions\": {}  # 各维度的分析结果\n        }\n        \n        for field, ents in item.items():\n            merged[field].extend(e[\"text\"] for e in ents)\n            result_by_id[comment_id][\"dimensions\"][field] = [e[\"text\"] for e in ents]\n            \n    # 增强提取 - 基于特征词和上下文\n    enhanced = {k: [] for k in SCHEMA}\n    for i, text in enumerate(batch):\n        comment_id = batch_ids[i]\n        # 对每个维度进行特征词增强\n        result_by_id[comment_id][\"enhanced_dimensions\"] = {}\n        \n        for dimension, keywords in FEATURE_WORDS.items():\n            result_by_id[comment_id][\"enhanced_dimensions\"][dimension] = []\n            \n            for keyword in keywords:\n                if keyword in text:\n                    # 找出关键词所在的上下文\n                    start_pos = text.find(keyword)\n                    # 提取关键词周围的上下文（前后15个字符）\n                    context_start = max(0, start_pos - 15)\n                    context_end = min(len(text), start_pos + len(keyword) + 15)\n                    context = text[context_start:context_end]\n                    enhanced[dimension].append(context)\n                    \n                    # 记录特征词的位置和上下文\n                    result_by_id[comment_id][\"enhanced_dimensions\"][dimension].append({\n                        \"keyword\": keyword,\n                        \"position\": start_pos,\n                        \"context\": context\n                    })\n    \n    return {\n        \"ids\": batch_ids,\n        \"raw\": merged,\n        \"enhanced\": enhanced,\n        \"by_id\": result_by_id\n    }\n\ndef generate_topic_document_matrix(merged_results, comments_df):\n    \"\"\"\n    生成类似LDA的主题-文档矩阵\n    \"\"\"\n    # 将评论ID与主题维度的出现频率关联\n    topic_doc_matrix = {}\n    \n    # 对每个评论，计算各主题维度的相关度\n    for comment_id, comment_data in merged_results[\"by_id\"].items():\n        topic_doc_matrix[comment_id] = {dimension: 0 for dimension in SCHEMA[2:]}  # 跳过主题关键词和情感倾向\n        \n        # 基于UIE提取结果计算相关度\n        for dimension in SCHEMA[2:]:\n            # 考虑原始UIE提取结果\n            if dimension in comment_data.get(\"dimensions\", {}) and comment_data[\"dimensions\"][dimension]:\n                topic_doc_matrix[comment_id][dimension] += len(comment_data[\"dimensions\"][dimension]) * 1.5  # 原始UIE结果权重更高\n            \n            # 考虑增强维度\n            if dimension in comment_data.get(\"enhanced_dimensions\", {}) and comment_data[\"enhanced_dimensions\"][dimension]:\n                topic_doc_matrix[comment_id][dimension] += len(comment_data[\"enhanced_dimensions\"][dimension])\n    \n    # 计算每个文档的主导主题\n    dominant_topics = {}\n    for comment_id, topics in topic_doc_matrix.items():\n        if any(topics.values()):  # 确保至少有一个主题得分不为0\n            dominant_topic = max(topics.items(), key=lambda x: x[1])\n            dominant_topics[comment_id] = {\n                \"topic\": dominant_topic[0],\n                \"score\": dominant_topic[1]\n            }\n        else:\n            dominant_topics[comment_id] = {\"topic\": \"未分类\", \"score\": 0}\n            \n    # 转换为DataFrame\n    topic_doc_df = pd.DataFrame.from_dict(topic_doc_matrix, orient=\"index\")\n    \n    # 合并原始评论文本\n    topic_doc_df = pd.DataFrame.from_dict(topic_doc_matrix, orient=\"index\")\n    \n    # 添加主导主题列\n    topic_doc_df[\"dominant_topic\"] = [dominant_topics[idx][\"topic\"] for idx in topic_doc_df.index]\n    topic_doc_df[\"topic_score\"] = [dominant_topics[idx][\"score\"] for idx in topic_doc_df.index]\n    \n    # 合并原始评论文本\n    if \"评论ID\" in comments_df.columns:\n        topic_doc_df = topic_doc_df.merge(\n            comments_df[[\"评论ID\", \"评论\"]], \n            left_index=True, \n            right_on=\"评论ID\",\n            how=\"left\"\n        )\n    \n    # 计算主题间的相似度矩阵\n    topic_similarity = pd.DataFrame(\n        cosine_similarity(topic_doc_df[SCHEMA[2:]].T),\n        index=SCHEMA[2:],\n        columns=SCHEMA[2:]\n    )\n    \n    return topic_doc_df, topic_similarity, dominant_topics\n\ndef extract_sentiment_analysis(all_results):\n    \"\"\"提取情感分析结果并计算统计信息\"\"\"\n    sentiment_data = {}\n    sentiment_by_topic = {topic: {\"正面\": 0, \"负面\": 0, \"中性\": 0} for topic in SCHEMA[2:]}\n    \n    # 遍历每条评论，提取情感信息\n    for comment_id, data in all_results[\"by_id\"].items():\n        # 获取情感倾向\n        sentiments = data.get(\"dimensions\", {}).get(\"情感倾向\", [])\n        dominant_sentiment = \"中性\"  # 默认中性\n        \n        # 判断主要情感倾向\n        if sentiments:\n            pos_count = sentiments.count(\"正面\") + sentiments.count(\"积极\") + sentiments.count(\"好评\")\n            neg_count = sentiments.count(\"负面\") + sentiments.count(\"消极\") + sentiments.count(\"差评\")\n            \n            if pos_count > neg_count:\n                dominant_sentiment = \"正面\"\n            elif neg_count > pos_count:\n                dominant_sentiment = \"负面\"\n        \n        # 记录该评论的主要情感\n        sentiment_data[comment_id] = dominant_sentiment\n        \n        # 统计不同主题下的情感分布\n        # 找到该评论的主导主题\n        max_score = 0\n        dominant_topic = None\n        \n        for topic in SCHEMA[2:]:\n            topic_score = 0\n            if topic in data.get(\"dimensions\", {}):\n                topic_score += len(data[\"dimensions\"][topic]) * 1.5\n            if topic in data.get(\"enhanced_dimensions\", {}):\n                topic_score += len(data[\"enhanced_dimensions\"][topic])\n                \n            if topic_score > max_score:\n                max_score = topic_score\n                dominant_topic = topic\n        \n        # 只有当有主导主题时才统计\n        if dominant_topic and max_score > 0:\n            sentiment_by_topic[dominant_topic][dominant_sentiment] += 1\n    \n    return sentiment_data, sentiment_by_topic\n\ndef extract_keyword_co_occurrence(all_results):\n    \"\"\"提取关键词共现信息\"\"\"\n    # 统计各维度关键词出现次数\n    keyword_counts = {dimension: Counter() for dimension in SCHEMA[2:]}\n    for comment_id, data in all_results[\"by_id\"].items():\n        for dimension in SCHEMA[2:]:\n            if dimension in data.get(\"dimensions\", {}):\n                keywords = data[\"dimensions\"][dimension]\n                for kw in keywords:\n                    keyword_counts[dimension][kw] += 1\n            \n            if dimension in data.get(\"enhanced_dimensions\", {}):\n                for item in data[\"enhanced_dimensions\"][dimension]:\n                    keyword_counts[dimension][item[\"keyword\"]] += 1\n    \n    # 统计关键词之间的共现关系\n    co_occurrence = {}\n    \n    for comment_id, data in all_results[\"by_id\"].items():\n        # 获取评论中出现的所有关键词\n        all_keywords = []\n        \n        for dimension in SCHEMA[2:]:\n            if dimension in data.get(\"dimensions\", {}):\n                all_keywords.extend([(kw, dimension) for kw in data[\"dimensions\"][dimension]])\n            \n            if dimension in data.get(\"enhanced_dimensions\", {}):\n                all_keywords.extend([(item[\"keyword\"], dimension) for item in data[\"enhanced_dimensions\"][dimension]])\n        \n        # 统计共现\n        for i, (kw1, dim1) in enumerate(all_keywords):\n            for kw2, dim2 in all_keywords[i+1:]:\n                if kw1 != kw2:  # 避免自己和自己共现\n                    key = (kw1, dim1, kw2, dim2)\n                    co_occurrence[key] = co_occurrence.get(key, 0) + 1\n    \n    # 转换为DataFrame格式\n    co_occur_records = []\n    for (kw1, dim1, kw2, dim2), count in co_occurrence.items():\n        if count >= 2:  # 只保留共现次数大于等于2的\n            co_occur_records.append({\n                \"keyword1\": kw1,\n                \"dimension1\": dim1,\n                \"keyword2\": kw2,\n                \"dimension2\": dim2,\n                \"co_occurrence_count\": count\n            })\n    \n    co_occur_df = pd.DataFrame(co_occur_records)\n    return keyword_counts, co_occur_df\n\ndef save_checkpoint(name, data):\n    \"\"\"保存检查点数据\"\"\"\n    checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"{name}.pickle\")\n    with open(checkpoint_path, \"wb\") as f:\n        pickle.dump(data, f)\n    logging.info(f\"检查点已保存: {checkpoint_path}\")\n\ndef load_checkpoint(name):\n    \"\"\"加载检查点数据\"\"\"\n    checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"{name}.pickle\")\n    if os.path.exists(checkpoint_path):\n        with open(checkpoint_path, \"rb\") as f:\n            data = pickle.load(f)\n        logging.info(f\"已加载检查点: {checkpoint_path}\")\n        return data\n    return None\n\ndef main():\n    # 创建进度管理器\n    progress_mgr = ProgressManager()\n    \n    # 创建输出目录\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n    \n    # 1. 读取 CSV 并提取评论列\n    df = None\n    comments = []\n    comment_ids = []\n    \n    if not progress_mgr.is_stage_completed(\"load_data\"):\n        logging.info(\"开始加载数据...\")\n        df = pd.read_csv(CSV_PATH, encoding=\"utf-8\")\n        if \"评论ID\" not in df.columns:\n            df[\"评论ID\"] = [f\"comment_{i}\" for i in range(len(df))]\n        \n        comments = df[\"评论\"].dropna().astype(str).tolist()\n        comment_ids = df[\"评论ID\"].tolist()\n        logging.info(f\"已加载 {len(comments)} 条评论\")\n        \n        # 保存原始数据的副本\n        df.to_csv(os.path.join(OUTPUT_DIR, f\"{OUTPUT_FILE_PREFIX}_raw_data.csv\"), index=False, encoding=\"utf-8\")\n        \n        # 保存数据检查点\n        save_checkpoint(\"raw_data\", {\"df\": df, \"comments\": comments, \"comment_ids\": comment_ids})\n        progress_mgr.mark_stage_complete(\"load_data\")\n    else:\n        logging.info(\"加载数据阶段已完成，从检查点恢复...\")\n        checkpoint_data = load_checkpoint(\"raw_data\")\n        if checkpoint_data:\n            df = checkpoint_data[\"df\"]\n            comments = checkpoint_data[\"comments\"]\n            comment_ids = checkpoint_data[\"comment_ids\"]\n            logging.info(f\"已从检查点恢复 {len(comments)} 条评论数据\")\n        else:\n            logging.error(\"无法加载数据检查点，重新开始加载数据...\")\n            # 重置进度并重新运行该阶段\n            progress_mgr.current_progress[\"stages\"][\"load_data\"] = False\n            return main()\n\n    # 2. 切分成多个批次并进行UIE抽取\n    all_results = {\n        \"ids\": [],\n        \"raw\": {k: [] for k in SCHEMA},\n        \"enhanced\": {k: [] for k in SCHEMA},\n        \"by_id\": {}\n    }\n    \n    if not progress_mgr.is_stage_completed(\"uie_extraction\"):\n        # 检查是否有缓存结果\n        cache_path = os.path.join(OUTPUT_DIR, f\"{OUTPUT_FILE_PREFIX}_uie_results.pickle\")\n        if os.path.exists(cache_path):\n            logging.info(f\"找到缓存结果，从 {cache_path} 加载\")\n            with open(cache_path, \"rb\") as f:\n                all_results = pickle.load(f)\n            logging.info(f\"已加载 {len(all_results['by_id'])} 条评论的分析结果\")\n            \n            # 检查是否所有评论都已处理\n            processed_ids = set(all_results[\"by_id\"].keys())\n            all_ids = set(comment_ids)\n            unprocessed_ids = all_ids - processed_ids\n            \n            # 如果有未处理的评论，继续处理\n            if unprocessed_ids:\n                logging.info(f\"发现 {len(unprocessed_ids)} 条评论尚未处理，继续处理...\")\n                unprocessed_indices = [i for i, cid in enumerate(comment_ids) if cid in unprocessed_ids]\n                unprocessed_comments = [comments[i] for i in unprocessed_indices]\n                unprocessed_comment_ids = [comment_ids[i] for i in unprocessed_indices]\n                \n                # 切分未处理的部分\n                batches = [\n                    (unprocessed_comment_ids[i:i+BATCH_SIZE], unprocessed_comments[i:i+BATCH_SIZE])\n                    for i in range(0, len(unprocessed_comments), BATCH_SIZE)\n                ]\n                \n                # 继续处理未处理的批次\n                with ProcessPoolExecutor(\n                    max_workers=NUM_WORKERS,\n                    initializer=init_worker,\n                    initargs=(DEVICE_ID,)\n                ) as executor:\n                    # 使用tqdm显示进度\n                    completed_batches = 0\n                    total_batches = len(batches)\n                    progress_mgr.update_batch_progress(total_batches, completed_batches)\n                    \n                    batch_iter = executor.map(process_batch, batches)\n                    for result in tqdm(batch_iter, total=total_batches, desc=\"继续UIE提取\"):\n                        all_results[\"ids\"].extend(result[\"ids\"])\n                        progress_mgr.add_processed_ids(result[\"ids\"])\n                        \n                        for k in SCHEMA:\n                            all_results[\"raw\"][k].extend(result[\"raw\"].get(k, []))\n                            all_results[\"enhanced\"][k].extend(result[\"enhanced\"].get(k, []))\n                        all_results[\"by_id\"].update(result[\"by_id\"])\n                        \n                        # 更新进度\n                        completed_batches += 1\n                        progress_mgr.update_batch_progress(total_batches, completed_batches)\n                        \n                        # 每处理10个批次保存一次中间结果\n                        if completed_batches % 10 == 0 or completed_batches == total_batches:\n                            # 保存UIE结果\n                            with open(cache_path, \"wb\") as f:\n                                pickle.dump(all_results, f)\n                            logging.info(f\"UIE分析中间结果已保存到缓存：{cache_path}\")\n                        \n                        # 检查中断标志\n                        if INTERRUPT_FLAG:\n                            logging.warning(\"检测到中断请求，安全退出处理...\")\n                            # 保存当前进度\n                            with open(cache_path, \"wb\") as f:\n                                pickle.dump(all_results, f)\n                            logging.info(f\"当前进度已保存，下次可继续处理\")\n                            return\n            \n            # 所有评论处理完成，标记阶段完成\n            progress_mgr.mark_stage_complete(\"uie_extraction\")\n        else:\n            logging.info(\"未找到缓存结果，开始运行UIE分析\")\n            # 切分成多个批次\n            batches = [\n                (comment_ids[i:i+BATCH_SIZE], comments[i:i+BATCH_SIZE])\n                for i in range(0, len(comments), BATCH_SIZE)\n            ]\n\n            # 并行抽取\n            with ProcessPoolExecutor(\n                max_workers=NUM_WORKERS,\n                initializer=init_worker,\n                initargs=(DEVICE_ID,)\n            ) as executor:\n                # 使用tqdm显示进度\n                completed_batches = 0\n                total_batches = len(batches)\n                progress_mgr.update_batch_progress(total_batches, completed_batches)\n                \n                batch_iter = executor.map(process_batch, batches)\n                for result in tqdm(batch_iter, total=total_batches, desc=\"UIE提取\"):\n                    all_results[\"ids\"].extend(result[\"ids\"])\n                    progress_mgr.add_processed_ids(result[\"ids\"])\n                    \n                    for k in SCHEMA:\n                        all_results[\"raw\"][k].extend(result[\"raw\"].get(k, []))\n                        all_results[\"enhanced\"][k].extend(result[\"enhanced\"].get(k, []))\n                    all_results[\"by_id\"].update(result[\"by_id\"])\n                    \n                    # 更新进度\n                    completed_batches += 1\n                    progress_mgr.update_batch_progress(total_batches, completed_batches)\n                    \n                    # 每处理10个批次保存一次中间结果\n                    if completed_batches % 10 == 0 or completed_batches == total_batches:\n                        # 保存UIE结果\n                        with open(cache_path, \"wb\") as f:\n                            pickle.dump(all_results, f)\n                        logging.info(f\"UIE分析中间结果已保存到缓存：{cache_path}\")\n                    \n                    # 检查中断标志\n                    if INTERRUPT_FLAG:\n                        logging.warning(\"检测到中断请求，安全退出处理...\")\n                        # 保存当前进度\n                        with open(cache_path, \"wb\") as f:\n                            pickle.dump(all_results, f)\n                        logging.info(f\"当前进度已保存，下次可继续处理\")\n                        return\n                \n                # UIE分析完成，保存结果并标记阶段完成\n                with open(cache_path, \"wb\") as f:\n                    pickle.dump(all_results, f)\n                logging.info(f\"UIE分析结果已保存到缓存：{cache_path}\")\n                progress_mgr.mark_stage_complete(\"uie_extraction\")\n    else:\n        # 从缓存加载UIE结果\n        cache_path = os.path.join(OUTPUT_DIR, f\"{OUTPUT_FILE_PREFIX}_uie_results.pickle\")\n        if os.path.exists(cache_path):\n            logging.info(f\"加载UIE分析结果从缓存: {cache_path}\")\n            with open(cache_path, \"rb\") as f:\n                all_results = pickle.load(f)\n            logging.info(f\"已加载 {len(all_results['by_id'])} 条评论的分析结果\")\n        else:\n            logging.error(\"无法找到UIE分析结果缓存，但进度显示已完成，将重置进度\")\n            # 重置进度并重新运行该阶段\n            progress_mgr.current_progress[\"stages\"][\"uie_extraction\"] = False\n            return main()\n\n    # 4.1 提取详细的评论级别数据\n    if not progress_mgr.is_stage_completed(\"comment_level_data\"):\n        logging.info(\"开始生成评论级别详细数据...\")\n        try:\n            comment_level_data = []\n            for comment_id, data in all_results[\"by_id\"].items():\n                row = {\n                    \"评论ID\": comment_id,\n                    \"评论文本\": data.get(\"text\", \"\"),\n                }\n                \n                # 添加各维度的提取结果\n                for dimension in SCHEMA:\n                    extracted = data.get(\"dimensions\", {}).get(dimension, [])\n                    row[f\"{dimension}_提取结果\"] = \"|\".join(extracted) if extracted else \"\"\n                    \n                    # 添加增强特征的信息\n                    enhanced = data.get(\"enhanced_dimensions\", {}).get(dimension, [])\n                    row[f\"{dimension}_增强特征\"] = \"|\".join([item.get(\"keyword\", \"\") for item in enhanced]) if enhanced else \"\"\n                \n                comment_level_data.append(row)\n            \n            # 保存评论级别的详细数据\n            comment_level_df = pd.DataFrame(comment_level_data)\n            comment_level_file = os.path.join(OUTPUT_DIR, f\"{OUTPUT_FILE_PREFIX}_comment_level_data.csv\")\n            comment_level_df.to_csv(comment_level_file, index=False, encoding=\"utf-8\")\n            logging.info(f\"评论级别数据已保存到: {comment_level_file}\")\n            \n            # 保存检查点和标记阶段完成\n            save_checkpoint(\"comment_level_data\", comment_level_df)\n            progress_mgr.mark_stage_complete(\"comment_level_data\")\n            \n            # 检查中断标志\n            if INTERRUPT_FLAG:\n                logging.warning(\"检测到中断请求，安全退出处理...\")\n                return\n        except Exception as e:\n            logging.error(f\"生成评论级别数据时出错: {e}\")\n    else:\n        logging.info(\"评论级别数据生成阶段已完成\")\n\n    # 4.2 生成维度频次统计\n    if not progress_mgr.is_stage_completed(\"dimension_stats\"):\n        logging.info(\"开始生成维度频次统计...\")\n        try:\n            dimension_stats = {}\n            for dimension in SCHEMA:\n                # 统计原始UIE提取\n                raw_count = Counter(all_results[\"raw\"].get(dimension, []))\n                # 统计增强特征\n                enhanced_count = Counter()\n                for comment_id, data in all_results[\"by_id\"].items():\n                    for item in data.get(\"enhanced_dimensions\", {}).get(dimension, []):\n                        enhanced_count[item.get(\"keyword\", \"\")] += 1\n                \n                # 合并两种统计\n                combined_count = raw_count.copy()\n                for k, v in enhanced_count.items():\n                    combined_count[k] = combined_count.get(k, 0) + v\n                \n                dimension_stats[dimension] = {\n                    \"raw\": dict(raw_count.most_common(20)),\n                    \"enhanced\": dict(enhanced_count.most_common(20)),\n                    \"combined\": dict(combined_count.most_common(20))\n                }\n            \n            # 保存维度统计\n            dimension_stats_file = os.path.join(OUTPUT_DIR, f\"{OUTPUT_FILE_PREFIX}_dimension_stats.json\")\n            with open(dimension_stats_file, \"w\", encoding=\"utf-8\") as f:\n                json.dump(dimension_stats, f, ensure_ascii=False, indent=2)\n            logging.info(f\"维度统计数据已保存到: {dimension_stats_file}\")\n            \n            # 保存检查点和标记阶段完成\n            save_checkpoint(\"dimension_stats\", dimension_stats)\n            progress_mgr.mark_stage_complete(\"dimension_stats\")\n            \n            # 检查中断标志\n            if INTERRUPT_FLAG:\n                logging.warning(\"检测到中断请求，安全退出处理...\")\n                return\n        except Exception as e:\n            logging.error(f\"生成维度统计时出错: {e}\")\n    else:\n        logging.info(\"维度统计生成阶段已完成\")\n\n    # 4.3 生成类似于LDA的主题-文档矩阵\n    topic_doc_df = None\n    topic_similarity = None\n    dominant_topics = None\n    if not progress_mgr.is_stage_completed(\"topic_document\"):\n        logging.info(\"开始生成主题-文档矩阵...\")\n        try:\n            # 生成类似于LDA的主题-文档矩阵\n            topic_doc_df, topic_similarity, dominant_topics = generate_topic_document_matrix(all_results, df)\n            \n            # 保存主题-文档矩阵\n            topic_doc_file = os.path.join(OUTPUT_DIR, f\"{OUTPUT_FILE_PREFIX}_topic_document_matrix.csv\")\n            topic_doc_df.to_csv(topic_doc_file, index=True, encoding=\"utf-8\")\n            logging.info(f\"主题-文档矩阵已保存到: {topic_doc_file}\")\n            \n            # 保存主题相似度矩阵\n            similarity_file = os.path.join(OUTPUT_DIR, f\"{OUTPUT_FILE_PREFIX}_topic_similarity.csv\")\n            topic_similarity.to_csv(similarity_file, encoding=\"utf-8\")\n            logging.info(f\"主题相似度矩阵已保存到: {similarity_file}\")\n            \n            # 主题分布统计\n            topic_distribution = Counter([info[\"topic\"] for info in dominant_topics.values()])\n            topic_distribution_df = pd.DataFrame({\n                \"主题\": list(topic_distribution.keys()),\n                \"评论数量\": list(topic_distribution.values())\n            })\n            distribution_file = os.path.join(OUTPUT_DIR, f\"{OUTPUT_FILE_PREFIX}_topic_distribution.csv\")\n            topic_distribution_df.to_csv(distribution_file, index=False, encoding=\"utf-8\")\n            logging.info(f\"主题分布统计已保存到: {distribution_file}\")\n            \n            # 保存检查点和标记阶段完成\n            save_checkpoint(\"topic_document\", {\n                \"topic_doc_df\": topic_doc_df,\n                \"topic_similarity\": topic_similarity,\n                \"dominant_topics\": dominant_topics,\n                \"topic_distribution\": topic_distribution\n            })\n            progress_mgr.mark_stage_complete(\"topic_document\")\n            \n            # 检查中断标志\n            if INTERRUPT_FLAG:\n                logging.warning(\"检测到中断请求，安全退出处理...\")\n                return\n        except Exception as e:\n            logging.error(f\"生成主题-文档矩阵时出错: {e}\")\n    else:\n        logging.info(\"主题-文档矩阵生成阶段已完成\")\n        # 从检查点加载数据\n        topic_doc_data = load_checkpoint(\"topic_document\")\n        if topic_doc_data:\n            topic_doc_df = topic_doc_data.get(\"topic_doc_df\")\n            topic_similarity = topic_doc_data.get(\"topic_similarity\")\n            dominant_topics = topic_doc_data.get(\"dominant_topics\")\n\n    # 4.4 情感分析结果\n    sentiment_data = None\n    sentiment_by_topic = None\n    if not progress_mgr.is_stage_completed(\"sentiment_analysis\"):\n        logging.info(\"开始生成情感分析结果...\")\n        try:\n            # 情感分析结果\n            sentiment_data, sentiment_by_topic = extract_sentiment_analysis(all_results)\n            \n            # 保存评论级别情感分析\n            sentiment_df = pd.DataFrame({\n                \"评论ID\": list(sentiment_data.keys()),\n                \"情感倾向\": list(sentiment_data.values())\n            })\n            sentiment_file = os.path.join(OUTPUT_DIR, f\"{OUTPUT_FILE_PREFIX}_sentiment_analysis.csv\")\n            sentiment_df.to_csv(sentiment_file, index=False, encoding=\"utf-8\")\n            logging.info(f\"情感分析结果已保存到: {sentiment_file}\")\n            \n            # 保存主题-情感矩阵\n            sentiment_topic_df = pd.DataFrame(sentiment_by_topic).T\n            sentiment_topic_df.index.name = \"主题\"\n            sentiment_topic_df.reset_index(inplace=True)\n            sentiment_topic_file = os.path.join(OUTPUT_DIR, f\"{OUTPUT_FILE_PREFIX}_sentiment_by_topic.csv\")\n            sentiment_topic_df.to_csv(sentiment_topic_file, index=False, encoding=\"utf-8\")\n            logging.info(f\"主题-情感矩阵已保存到: {sentiment_topic_file}\")\n            \n            # 保存检查点和标记阶段完成\n            save_checkpoint(\"sentiment_analysis\", {\n                \"sentiment_data\": sentiment_data,\n                \"sentiment_by_topic\": sentiment_by_topic\n            })\n            progress_mgr.mark_stage_complete(\"sentiment_analysis\")\n            \n            # 检查中断标志\n            if INTERRUPT_FLAG:\n                logging.warning(\"检测到中断请求，安全退出处理...\")\n                return\n        except Exception as e:\n            logging.error(f\"生成情感分析结果时出错: {e}\")\n    else:\n        logging.info(\"情感分析结果生成阶段已完成\")\n        # 从检查点加载数据\n        sentiment_data_obj = load_checkpoint(\"sentiment_analysis\")\n        if sentiment_data_obj:\n            sentiment_data = sentiment_data_obj.get(\"sentiment_data\")\n            sentiment_by_topic = sentiment_data_obj.get(\"sentiment_by_topic\")\n\n    # 4.5 关键词共现分析\n    keyword_counts = None\n    co_occur_df = None\n    if not progress_mgr.is_stage_completed(\"keyword_analysis\"):\n        logging.info(\"开始生成关键词分析结果...\")\n        try:\n            # 关键词共现分析\n            keyword_counts, co_occur_df = extract_keyword_co_occurrence(all_results)\n            \n            # 保存关键词频率\n            for dimension, counts in keyword_counts.items():\n                counts_df = pd.DataFrame({\n                    \"关键词\": list(counts.keys()),\n                    \"频次\": list(counts.values())\n                })\n                counts_df.sort_values(\"频次\", ascending=False, inplace=True)\n                keyword_file = os.path.join(OUTPUT_DIR, f\"{OUTPUT_FILE_PREFIX}_{dimension}_keywords.csv\")\n                counts_df.to_csv(keyword_file, index=False, encoding=\"utf-8\")\n                logging.info(f\"维度 '{dimension}' 关键词分析已保存到: {keyword_file}\")\n            \n            # 保存关键词共现\n            co_occur_file = os.path.join(OUTPUT_DIR, f\"{OUTPUT_FILE_PREFIX}_keyword_co_occurrence.csv\")\n            co_occur_df.to_csv(co_occur_file, index=False, encoding=\"utf-8\")\n            logging.info(f\"关键词共现分析已保存到: {co_occur_file}\")\n            \n            # 保存检查点和标记阶段完成\n            save_checkpoint(\"keyword_analysis\", {\n                \"keyword_counts\": keyword_counts,\n                \"co_occur_df\": co_occur_df\n            })\n            progress_mgr.mark_stage_complete(\"keyword_analysis\")\n            \n            # 检查中断标志\n            if INTERRUPT_FLAG:\n                logging.warning(\"检测到中断请求，安全退出处理...\")\n                return\n        except Exception as e:\n            logging.error(f\"生成关键词分析结果时出错: {e}\")\n    else:\n        logging.info(\"关键词分析结果生成阶段已完成\")\n        # 从检查点加载数据\n        keyword_data = load_checkpoint(\"keyword_analysis\")\n        if keyword_data:\n            keyword_counts = keyword_data.get(\"keyword_counts\")\n            co_occur_df = keyword_data.get(\"co_occur_df\")\n\n    # 4.6 生成可视化基础数据\n    if not progress_mgr.is_stage_completed(\"visualization_data\"):\n        logging.info(\"开始生成可视化基础数据...\")\n        try:\n            # 确保我们有需要的所有数据\n            if not all([dominant_topics, sentiment_data, sentiment_by_topic, keyword_counts, topic_similarity]):\n                logging.warning(\"缺少生成可视化数据所需的某些组件，尝试从检查点恢复...\")\n                \n                # 尝试从检查点加载缺失的数据\n                topic_doc_data = load_checkpoint(\"topic_document\")\n                if topic_doc_data and not dominant_topics:\n                    dominant_topics = topic_doc_data.get(\"dominant_topics\")\n                    topic_similarity = topic_doc_data.get(\"topic_similarity\")\n                \n                sentiment_data_obj = load_checkpoint(\"sentiment_analysis\")\n                if sentiment_data_obj and not sentiment_data:\n                    sentiment_data = sentiment_data_obj.get(\"sentiment_data\")\n                    sentiment_by_topic = sentiment_data_obj.get(\"sentiment_by_topic\")\n                \n                keyword_data = load_checkpoint(\"keyword_analysis\")\n                if keyword_data and not keyword_counts:\n                    keyword_counts = keyword_data.get(\"keyword_counts\")\n            \n            # 检查是否已恢复所需的所有数据\n            if not all([dominant_topics, sentiment_data, sentiment_by_topic, keyword_counts, topic_similarity]):\n                logging.error(\"无法恢复生成可视化数据所需的所有组件，请重新运行前面的分析阶段\")\n                # 将前面的阶段标记为未完成\n                progress_mgr.current_progress[\"stages\"][\"topic_document\"] = False\n                progress_mgr.current_progress[\"stages\"][\"sentiment_analysis\"] = False\n                progress_mgr.current_progress[\"stages\"][\"keyword_analysis\"] = False\n                progress_mgr.save_progress()\n                return main()\n            \n            # 生成主题分布统计\n            topic_distribution = Counter([info[\"topic\"] for info in dominant_topics.values()])\n            \n            # 生成可视化基础数据\n            visualization_data = {\n                \"topic_distribution\": {\n                    \"labels\": list(topic_distribution.keys()),\n                    \"values\": list(topic_distribution.values())\n                },\n                \"sentiment_overall\": {\n                    \"labels\": [\"正面\", \"负面\", \"中性\"],\n                    \"values\": [\n                        list(sentiment_data.values()).count(\"正面\"),\n                        list(sentiment_data.values()).count(\"负面\"),\n                        list(sentiment_data.values()).count(\"中性\")\n                    ]\n                },\n                \"topic_sentiment\": {\n                    dim: {\n                        \"labels\": [\"正面\", \"负面\", \"中性\"],\n                        \"values\": [data[\"正面\"], data[\"负面\"], data[\"中性\"]]\n                    }\n                    for dim, data in sentiment_by_topic.items()\n                },\n                \"topic_similarity\": topic_similarity.to_dict() if hasattr(topic_similarity, 'to_dict') else {},\n                \"top_keywords\": {\n                    dim: list(counts.most_common(10))\n                    for dim, counts in keyword_counts.items()\n                },\n            }\n            \n            # 保存可视化数据\n            viz_file = os.path.join(OUTPUT_DIR, f\"{OUTPUT_FILE_PREFIX}_visualization_data.json\")\n            with open(viz_file, \"w\", encoding=\"utf-8\") as f:\n                json.dump(visualization_data, f, ensure_ascii=False, indent=2)\n            logging.info(f\"可视化基础数据已保存到: {viz_file}\")\n            \n            # 保存检查点和标记阶段完成\n            save_checkpoint(\"visualization_data\", visualization_data)\n            progress_mgr.mark_stage_complete(\"visualization_data\")\n            \n            # 检查中断标志\n            if INTERRUPT_FLAG:\n                logging.warning(\"检测到中断请求，安全退出处理...\")\n                return\n        except Exception as e:\n            logging.error(f\"生成可视化基础数据时出错: {e}\")\n    else:\n        logging.info(\"可视化基础数据生成阶段已完成\")\n\n    # 5. 创建数据摘要文件\n    if not progress_mgr.is_stage_completed(\"summary\"):\n        logging.info(\"开始生成数据摘要文件...\")\n        try:\n            summary_path = os.path.join(OUTPUT_DIR, \"README.md\")\n            with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n                f.write(\"# 无人驾驶网约车评论数据分析结果\\n\\n\")\n                f.write(f\"## 分析时间: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n                f.write(f\"## 数据来源: {CSV_PATH}\\n\")\n                f.write(f\"## 评论总数: {len(comments)}\\n\\n\")\n                \n                f.write(\"## 文件说明\\n\\n\")\n                f.write(\"本目录包含以下数据文件：\\n\\n\")\n                f.write(f\"1. `{OUTPUT_FILE_PREFIX}_raw_data.csv` - 原始评论数据\\n\")\n                f.write(f\"2. `{OUTPUT_FILE_PREFIX}_comment_level_data.csv` - 评论级别的详细分析结果\\n\")\n                f.write(f\"3. `{OUTPUT_FILE_PREFIX}_dimension_stats.json` - 各维度关键词统计\\n\")\n                f.write(f\"4. `{OUTPUT_FILE_PREFIX}_topic_document_matrix.csv` - 主题-文档矩阵（类LDA结果）\\n\")\n                f.write(f\"5. `{OUTPUT_FILE_PREFIX}_topic_similarity.csv` - 主题间相似度矩阵\\n\")\n                f.write(f\"6. `{OUTPUT_FILE_PREFIX}_topic_distribution.csv` - 主题分布统计\\n\")\n                f.write(f\"7. `{OUTPUT_FILE_PREFIX}_sentiment_analysis.csv` - 评论级别情感分析结果\\n\")\n                f.write(f\"8. `{OUTPUT_FILE_PREFIX}_sentiment_by_topic.csv` - 主题-情感分布矩阵\\n\")\n                f.write(f\"9. `{OUTPUT_FILE_PREFIX}_*_keywords.csv` - 各维度关键词频率\\n\")\n                f.write(f\"10. `{OUTPUT_FILE_PREFIX}_keyword_co_occurrence.csv` - 关键词共现分析\\n\")\n                f.write(f\"11. `{OUTPUT_FILE_PREFIX}_visualization_data.json` - 用于可视化的整合数据\\n\\n\")\n                \n                f.write(\"## 可视化建议\\n\\n\")\n                f.write(\"基于生成的数据，您可以创建以下可视化图表：\\n\\n\")\n                f.write(\"1. **主题分布图** - 使用饼图或柱状图展示 `topic_distribution.csv`\\n\")\n                f.write(\"2. **情感分析** - 使用环形图展示整体情感分布，使用堆叠柱状图展示各主题下的情感分布\\n\")\n                f.write(\"3. **主题相似度热力图** - 使用 `topic_similarity.csv` 创建热力图\\n\")\n                f.write(\"4. **关键词词云** - 使用各维度的关键词频率数据创建词云\\n\")\n                f.write(\"5. **关键词共现网络图** - 使用 `keyword_co_occurrence.csv` 创建网络关系图\\n\")\n                f.write(\"6. **主题-评论矩阵可视化** - 使用 `topic_document_matrix.csv` 创建热力图或散点图\\n\\n\")\n                \n                f.write(\"要进行可视化，推荐使用 Python 中的 Matplotlib, Seaborn, Plotly 或 Tableau, Power BI 等工具。\\n\")\n            \n            logging.info(f\"数据摘要文件已生成: {summary_path}\")\n            \n            # 标记阶段完成\n            progress_mgr.mark_stage_complete(\"summary\")\n            \n            # 检查中断标志\n            if INTERRUPT_FLAG:\n                logging.warning(\"检测到中断请求，安全退出处理...\")\n                return\n        except Exception as e:\n            logging.error(f\"生成数据摘要文件时出错: {e}\")\n    else:\n        logging.info(\"数据摘要生成阶段已完成\")\n    \n    # 所有阶段都已完成\n    logging.info(\"分析完成！所有结果已保存到: {}\".format(OUTPUT_DIR))\n    \n    # 打印数据文件列表\n    logging.info(\"\\n生成的数据文件：\")\n    for file in os.listdir(OUTPUT_DIR):\n        if file.startswith(OUTPUT_FILE_PREFIX):\n            logging.info(f\" - {file}\")\n            \n    logging.info(\"\\n断点续传检查点文件：\")\n    for file in os.listdir(CHECKPOINT_DIR):\n        logging.info(f\" - {file}\")\n\ndef print_progress_info():\n    \"\"\"打印当前进度信息\"\"\"\n    if os.path.exists(PROGRESS_FILE):\n        with open(PROGRESS_FILE, \"r\", encoding=\"utf-8\") as f:\n            progress = json.load(f)\n            \n        print(\"\\n当前分析进度:\")\n        print(\"=\"*50)\n        \n        # 打印阶段完成情况\n        for stage, completed in progress[\"stages\"].items():\n            status = \"✓ 已完成\" if completed else \"✗ 未完成\"\n            print(f\"{stage:<20}: {status}\")\n        \n        # 打印批处理进度\n        if \"batch_progress\" in progress:\n            batch_info = progress[\"batch_progress\"]\n            total = batch_info.get(\"total_batches\", 0)\n            completed = batch_info.get(\"completed_batches\", 0)\n            if total > 0:\n                percent = (completed / total) * 100\n                print(f\"\\n批处理进度: {completed}/{total} ({percent:.1f}%)\")\n        \n        # 打印最后运行时间\n        if progress.get(\"last_run\"):\n            print(f\"\\n上次运行时间: {progress['last_run']}\")\n        \n        print(\"=\"*50)\n    else:\n        print(\"\\n未找到进度文件，尚未开始分析或进度文件丢失\")\n\nif __name__ == \"__main__\":\n    # 如果指定了查看进度参数\n    if len(sys.argv) > 1 and sys.argv[1] == \"--progress\":\n        print_progress_info()\n    # 如果指定了重置进度参数\n    elif len(sys.argv) > 1 and sys.argv[1] == \"--reset\":\n        confirm = input(\"确定要重置所有分析进度吗？这将导致重新开始所有分析。(y/n): \")\n        if confirm.lower() == 'y':\n            pm = ProgressManager()\n            pm.reset_progress(confirm=True)\n            print(\"分析进度已重置！\")\n        else:\n            print(\"已取消重置操作\")\n    else:\n        # 正常运行分析\n        try:\n            main()\n            if INTERRUPT_FLAG:\n                print(\"\\n分析已暂停，可以通过运行同一脚本继续处理\")\n                print(\"查看当前进度: python uie_judge.py --progress\")\n            else:\n                print(\"\\n所有分析已成功完成！\")\n        except KeyboardInterrupt:\n            print(\"\\n程序被中断，下次可继续运行\")\n        except Exception as e:\n            logging.error(f\"发生错误: {str(e)}\")\n            import traceback\n            traceback.print_exc()\n","outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"B7844BC369A349D180853D4BD5A59EDC","notebookId":"681762dad4034699adc59cac","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"平台无gpu，使用本地电脑运行  \n\n![Image Name](https://cdn.kesci.com/upload/svqmhm2wnz.jpg?imageView2/0/w/960/h/960)  \n"},{"cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"4FC61B519BE24DD590C9913A15FBDA95","scrolled":false,"notebookId":"681762dad4034699adc59cac"},"source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\n# ========== 嵌入数据 ==========\ndata = {\n    '关键词': ['便宜', '价格', '优惠', '贵', '科技',\n             '安全', '事故', '危险', '路况', '刹车',\n             '技术', '系统', '稳定', '故障', '导航',\n             '服务', '礼貌', '态度', '接送', '卫生',\n             '牌照', '要求', '法规', '合法', '规定',\n             '空调', '空间', '环境', '舒适', '温度',\n             '安全', '共享', '数据', '摄像头', '监控'],\n    '频率': [1844, 800, 779, 698, 385,\n           1757, 998, 478, 90, 81,\n           968, 330, 171, 155, 89,\n           725, 143, 117, 44, 42,\n           260, 135, 107, 93, 58,\n           159, 115, 80, 31, 27,\n           1757, 330, 290, 119, 100],\n    '维度': ['价格评价'] * 5 + ['安全关注'] * 5 + ['技术可靠性'] * 5 +\n           ['服务体验'] * 5 + ['法规合规'] * 5 + ['舒适度'] * 5 + ['隐私保护'] * 5\n}\n\ndf = pd.DataFrame(data)\n\n# ========== 可视化 ==========\nplt.figure(figsize=(12, 8))\nsns.set(style=\"whitegrid\")\n\n# 用不同颜色区分维度\npalette = sns.color_palette(\"Set2\", n_colors=df['维度'].nunique())\n\nsns.barplot(data=df, x='频率', y='关键词', hue='维度', dodge=False, palette=palette)\n\nplt.title(\"各维度下高频关键词分布（Top 5）\", fontsize=16)\nplt.xlabel(\"关键词频率\", fontsize=13)\nplt.ylabel(\"关键词\", fontsize=13)\nplt.legend(title=\"关键词维度\", bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n","outputs":[{"output_type":"stream","name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 20851 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 38190 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 35789 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 39057 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 29575 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 20415 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 23452 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 20215 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 26684 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 20248 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 24800 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 36149 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 31185 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 25216 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 23433 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 20840 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 20107 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 25925 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 21361 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 38505 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 36335 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 20917 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 21049 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 36710 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 26415 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 31995 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 32479 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 31283 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 23450 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 38556 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 23548 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 33322 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 26381 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 21153 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 31036 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 35980 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 24577 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 24230 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 25509 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 36865 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 21355 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 29983 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 29260 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 29031 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 35201 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 27714 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 27861 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 35268 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 21512 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 31354 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 35843 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 38388 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 29615 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 22659 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 33298 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 36866 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 28201 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 20849 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 20139 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 25968 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 25454 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 25668 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 20687 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 22836 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 30417 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 25511 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 21508 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 32500 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 19979 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 39640 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 20998 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 24067 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 65288 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 65289 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 35780 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 27880 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 21487 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 38752 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 24615 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 20307 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 39564 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 38544 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 31169 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 20445 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 25252 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 20851 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 38190 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 35789 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 39057 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 29575 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 20415 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 23452 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 20215 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 26684 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 20248 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 24800 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:176: RuntimeWarning: Glyph 36149 missing from current font.\n  font.load_char(ord(s), flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 31185 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 25216 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 23433 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 20840 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 20107 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 25925 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 21361 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 38505 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 36335 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 20917 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 21049 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 36710 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 26415 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 31995 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 32479 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 31283 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 23450 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 38556 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 23548 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 33322 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 26381 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 21153 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 31036 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 35980 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 24577 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 24230 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 25509 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 36865 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 21355 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 29983 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 29260 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 29031 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 35201 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 27714 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 27861 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 35268 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 21512 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 31354 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 35843 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 38388 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 29615 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 22659 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 33298 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 36866 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 28201 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 20849 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 20139 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 25968 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 25454 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 25668 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 20687 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 22836 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 30417 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 25511 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 21508 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 32500 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 19979 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 39640 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 20998 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 24067 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 65288 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 65289 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 35780 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 27880 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 21487 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 38752 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 24615 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 20307 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 39564 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 38544 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 31169 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 20445 missing from current font.\n  font.set_text(s, 0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 25252 missing from current font.\n  font.set_text(s, 0, flags=flags)\n"},{"output_type":"display_data","data":{"text/plain":"<Figure size 864x576 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/4FC61B519BE24DD590C9913A15FBDA95/svqn4agm7u.png\">"},"metadata":{"needs_background":"light"}}],"execution_count":3},{"cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"16BEDEF83DF24B65ABB0E52615CECDCB","scrolled":false,"notebookId":"681762dad4034699adc59cac"},"source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.font_manager import FontProperties\n\n# —— 1. 嵌入数据 ——\ndata = {\n    '关键词': ['便宜','价格','优惠','贵','科技',\n             '安全','事故','危险','路况','刹车',\n             '技术','系统','稳定','故障','导航',\n             '服务','礼貌','态度','接送','卫生',\n             '牌照','要求','法规','合法','规定',\n             '空调','空间','环境','舒适','温度',\n             '安全','共享','数据','摄像头','监控'],\n    '频率': [1844,800,779,698,385,\n           1757,998,478,90,81,\n           968,330,171,155,89,\n           725,143,117,44,42,\n           260,135,107,93,58,\n           159,115,80,31,27,\n           1757,330,290,119,100],\n    '维度': ['价格评价']*5 + ['安全关注']*5 + ['技术可靠性']*5 +\n           ['服务体验']*5 + ['法规合规']*5 + ['舒适度']*5 + ['隐私保护']*5\n}\ndf = pd.DataFrame(data)\n\n# —— 2. 字体设置 ——\nfont_path = \"/home/mw/input/ch491739173/Ubuntu_18.04_SimHei.ttf\"\nfont_prop = FontProperties(fname=font_path)\n\nplt.rcParams['font.sans-serif'] = [font_prop.get_name()]\nplt.rcParams['axes.unicode_minus'] = False\nplt.rcParams['font.size']       = 14\nplt.rcParams['axes.titlesize']  = 20\nplt.rcParams['axes.labelsize']  = 16\nplt.rcParams['legend.fontsize'] = 14\n\n# —— 3. 绘图 —— \nplt.figure(figsize=(14,10))\nsns.set(style=\"whitegrid\")\npalette = sns.color_palette(\"Set2\", df['维度'].nunique())\n\nsns.barplot(\n    data=df, x='频率', y='关键词',\n    hue='维度', dodge=False, palette=palette\n)\n\nplt.title(\"各维度下高频关键词分布（Top 5）\", fontproperties=font_prop)\nplt.xlabel(\"关键词频率\", fontproperties=font_prop)\nplt.ylabel(\"关键词\", fontproperties=font_prop)\n\n# 强制坐标刻度用中文字体\nplt.xticks(fontproperties=font_prop, fontsize=14)\nplt.yticks(fontproperties=font_prop, fontsize=14)\n# 强制图例用中文字体\nplt.legend(prop=font_prop, title=\"维度\", title_fontsize=16, loc='upper right')\n\nplt.tight_layout()\nplt.show()\n","outputs":[{"output_type":"stream","name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8239 missing from current font.\n  font.set_text(s, 0.0, flags=flags)\n/opt/conda/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8239 missing from current font.\n  font.set_text(s, 0, flags=flags)\n"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x720 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/16BEDEF83DF24B65ABB0E52615CECDCB/svqn8v6t5.png\">"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","metadata":{"id":"E7BB673BD0154D61BDD924E16C94685B","notebookId":"681762dad4034699adc59cac","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":""},{"cell_type":"code","metadata":{"id":"EE421F9192654AE689AAB097B24472BB","notebookId":"681762dad4034699adc59cac","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.font_manager import FontProperties\n\n# ———— 1. 数据嵌入 ————\ndata = {\n    '关键词': [\n        '便宜','价格','优惠','贵','科技',\n        '安全','事故','危险','路况','刹车',\n        '技术','系统','稳定','故障','导航',\n        '服务','礼貌','态度','接送','卫生',\n        '牌照','要求','法规','合法','规定',\n        '空调','空间','环境','舒适','温度',\n        '安全','共享','数据','摄像头','监控'\n    ],\n    '频率': [\n        1844, 800, 779, 698, 385,\n        1757, 998, 478,  90,  81,\n         968, 330, 171, 155,  89,\n         725, 143, 117,  44,  42,\n         260, 135, 107,  93,  58,\n         159, 115,  80,  31,  27,\n        1757, 330, 290, 119, 100\n    ],\n    '维度': (\n        ['价格评价'] * 5 +\n        ['安全关注'] * 5 +\n        ['技术可靠性'] * 5 +\n        ['服务体验'] * 5 +\n        ['法规合规'] * 5 +\n        ['舒适度'] * 5 +\n        ['隐私保护'] * 5\n    )\n}\ndf = pd.DataFrame(data)\n\n# ———— 2. 中文字体 & 全局样式 ————\nfont_path = \"/home/mw/input/ch491739173/Ubuntu_18.04_SimHei.ttf\"\nfont_prop = FontProperties(fname=font_path)\n\nplt.rcParams['font.sans-serif']    = [font_prop.get_name()]  # 指定中文字体\nplt.rcParams['axes.unicode_minus'] = False                   # 解决负号显示问题\nplt.rcParams.update({\n    'axes.titlesize': 22,\n    'axes.labelsize': 22,\n    'xtick.labelsize': 22,\n    'ytick.labelsize': 22\n})\n\n# ———— 3. FacetGrid 分面条形图 ————\nsns.set(style=\"whitegrid\")\ng = sns.FacetGrid(\n    df,\n    col='维度',\n    col_wrap=4,\n    sharex=False,\n    sharey=False,\n    height=3.5,\n    aspect=1.2\n)\ng.map_dataframe(sns.barplot, x='频率', y='关键词', palette='viridis', orient='h')\n\n# ———— 4. 子图调整：数值标签 + 轴标签 + 强制 y 轴中文 ————\nmax_freq = df['频率'].max()\nfor ax in g.axes.flatten():\n    # 为每个条形添加数值标签\n    for p in ax.patches:\n        w = p.get_width()\n        ax.text(\n            w + max_freq*0.01,\n            p.get_y() + p.get_height()/2,\n            f\"{int(w)}\",\n            va='center',\n            fontproperties=font_prop,\n            fontsize=12\n        )\n    # x 轴标签\n    ax.set_xlabel('频率', fontproperties=font_prop, fontsize=16)\n    # y 轴刻度标签手动指定中文字体\n    y_labels = [t.get_text() for t in ax.get_yticklabels()]\n    ax.set_yticklabels(y_labels, fontproperties=font_prop, fontsize=14)\n\n# ———— 5. 子图标题 & 布局 ————\ng.set_titles(col_template='{col_name}', fontproperties=font_prop, size=18)\nplt.tight_layout(h_pad=2, w_pad=1)\nplt.show()\n","outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1209.6x504 with 7 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/EE421F9192654AE689AAB097B24472BB/svqns7e58l.png\">"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","metadata":{"id":"F17B353170204E739D009B502E323F33","notebookId":"681762dad4034699adc59cac","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":""},{"cell_type":"code","metadata":{"id":"31600DB3DC464AA2A62DE3CD27D4C106","notebookId":"681762dad4034699adc59cac","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib import font_manager\n\n# 加载中文字体\nfont_path = \"/home/mw/input/ch491739173/Ubuntu_18.04_SimHei.ttf\"\nchinese_font = font_manager.FontProperties(fname=font_path, size=14)\n\n# 创建数据\ndata = {\n    '': ['安全关注', '舒适度', '价格评价', '服务体验', '技术可靠性', '法规合规', '隐私保护'],\n    '安全关注': [0.9999999999999943, 0.036495967547236004, 0.07490051068157604, 0.05396010202700443, 0.07523861763866395, 0.034797975927453276, 0.5865885533261261],\n    '舒适度': [0.036495967547236004, 0.9999999999999969, 0.0698092513502067, 0.055743124472060986, 0.019619050328084912, 0.011802025077377874, 0.028334600756232894],\n    '价格评价': [0.07490051068157604, 0.0698092513502067, 0.9999999999999997, 0.10206529180241004, 0.10552236197584401, 0.03140387248548638, 0.06972175771755759],\n    '服务体验': [0.05396010202700443, 0.055743124472060986, 0.10206529180241004, 1.0000000000000038, 0.035337001810151196, 0.016291080476171286, 0.033449352934405506],\n    '技术可靠性': [0.07523861763866395, 0.019619050328084912, 0.10552236197584401, 0.035337001810151196, 1.0000000000000004, 0.020962386250275113, 0.06286354999654796],\n    '法规合规': [0.034797975927453276, 0.011802025077377874, 0.03140387248548638, 0.016291080476171286, 0.020962386250275113, 1.0000000000000056, 0.018799235342177655],\n    '隐私保护': [0.5865885533261261, 0.028334600756232894, 0.06972175771755759, 0.033449352934405506, 0.06286354999654796, 0.018799235342177655, 1.0000000000000016]\n}\n\ndf = pd.DataFrame(data)\ndf.set_index('', inplace=True)\n\n# 创建上三角掩码\nmask = np.triu(np.ones_like(df, dtype=bool))\n\n# 设置图形\nplt.figure(figsize=(12, 10), dpi=300)\n\n# 创建热力图\nheatmap = sns.heatmap(\n    df, \n    annot=True, \n    fmt=\".2f\", \n    cmap=\"YlGnBu\",\n    mask=mask, \n    vmin=0, \n    vmax=1,\n    linewidths=0.8,\n    linecolor='white',\n    annot_kws={\n        \"size\": 14,\n        \"color\": \"black\",\n        \"fontproperties\": chinese_font  # 为注释文本指定字体\n    },\n    cbar_kws={\n        \"shrink\": 0.8,\n        \"label\": \"相似度\"\n    }\n)\n\n# 自定义标题\ntitle = plt.title('自动驾驶网约车评论主题相似度矩阵', pad=25, fontsize=20, fontweight='bold')\ntitle.set_fontproperties(font_manager.FontProperties(fname=font_path, size=20))\n\n# 自定义坐标轴标签\nfor label in heatmap.get_xticklabels():\n    label.set_fontproperties(chinese_font)\n    label.set_size(14)\n    \nfor label in heatmap.get_yticklabels():\n    label.set_fontproperties(chinese_font)\n    label.set_size(14)\n\n# 自定义颜色条标签\ncbar = heatmap.collections[0].colorbar\ncbar.ax.yaxis.label.set_fontproperties(chinese_font)\ncbar.ax.yaxis.label.set_size(14)\nfor label in cbar.ax.get_yticklabels():\n    label.set_fontproperties(chinese_font)\n    label.set_size(12)\n\n# 添加边框\nfor _, spine in heatmap.spines.items():\n    spine.set_visible(True)\n    spine.set_linewidth(1.5)\n\n# 调整布局\nplt.tight_layout()\n\n# 保存图形\nplt.savefig(\"similarity_matrix_improved.jpg\", dpi=300, bbox_inches='tight', quality=95)\nplt.show()","outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 3600x3000 with 2 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/31600DB3DC464AA2A62DE3CD27D4C106/svrq2433td.png\">"},"metadata":{"needs_background":"light"}}],"execution_count":5}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}
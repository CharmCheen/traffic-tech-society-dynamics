{"cells":[{"cell_type":"code","metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2025-03-06T11:55:56.307208Z","iopub.status.busy":"2025-03-06T11:55:56.306596Z","iopub.status.idle":"2025-03-06T11:55:56.311376Z","shell.execute_reply":"2025-03-06T11:55:56.310948Z"},"hide_input":true,"jupyter":{"source_hidden":true},"papermill":{"duration":0.099923,"end_time":"2025-03-06T11:55:56.312334","exception":false,"start_time":"2025-03-06T11:55:56.212411","status":"completed"},"tags":[],"id":"E7D53935E60E42AFAC9C162B1D95BDB0","scrolled":false,"slideshow":{"slide_type":"slide"},"notebookId":"67ca4cac8fded24f7f8a6580","trusted":true},"source":"mountedDB = {}","outputs":[],"execution_count":1},{"cell_type":"markdown","metadata":{"id":"00D2D72D13B44B11B4C1BB961DAB87C7","jupyter":{},"notebookId":"67ca4cac8fded24f7f8a6580","papermill":{"duration":0.119247,"end_time":"2025-03-06T11:55:56.537157","exception":false,"start_time":"2025-03-06T11:55:56.417910","status":"completed"},"runtime":{"status":"default","execution_status":null,"is_visible":false},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":"## 欢迎进入 ModelWhale Notebook  \n\n这里你可以编写代码，文档  \n\n### 关于文件目录  \n\n\n**project**：project 目录是本项目的工作空间，可以把将项目运行有关的所有文件放在这里，目录中文件的增、删、改操作都会被保留  \n\n\n**input**：input 目录是数据集的挂载位置，所有挂载进项目的数据集都在这里，未挂载数据集时 input 目录被隐藏  \n\n\n**temp**：temp 目录是临时磁盘空间，训练或分析过程中产生的不必要文件可以存放在这里，目录中的文件不会保存  \n"},{"cell_type":"code","metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2025-03-06T11:55:56.729975Z","iopub.status.busy":"2025-03-06T11:55:56.729380Z","iopub.status.idle":"2025-03-06T18:07:05.914180Z","shell.execute_reply":"2025-03-06T18:07:05.913688Z"},"id":"94405372A6F04829966E7E70C2328397","jupyter":{"source_hidden":true},"notebookId":"67ca4cac8fded24f7f8a6580","papermill":{"duration":22269.276138,"end_time":"2025-03-06T18:07:05.915216","exception":false,"start_time":"2025-03-06T11:55:56.639078","status":"completed"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"import os\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (\n    Input, LSTM, Dense, Embedding, Dropout, Bidirectional, Layer\n)\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport re\n\n# 自定义Attention层示例\nclass AttentionLayer(Layer):\n    def __init__(self, **kwargs):\n        super(AttentionLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.W = self.add_weight(\n            name='att_weight',\n            shape=(input_shape[-1], input_shape[-1]),\n            initializer='glorot_uniform',\n            trainable=True\n        )\n        self.b = self.add_weight(\n            name='att_bias',\n            shape=(input_shape[-1],),\n            initializer='zeros',\n            trainable=True\n        )\n        super(AttentionLayer, self).build(input_shape)\n\n    def call(self, inputs, mask=None):\n        # inputs.shape = (batch_size, timesteps, hidden_size)\n        x = tf.tensordot(inputs, self.W, axes=[2, 0]) + self.b\n        x = tf.nn.tanh(x)\n        # 计算注意力分数\n        scores = tf.nn.softmax(tf.reduce_sum(x, axis=2), axis=1)\n        # 利用注意力分数计算加权输出\n        scores = tf.expand_dims(scores, axis=2)\n        context = inputs * scores\n        return tf.reduce_sum(context, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], input_shape[-1])\n\n# 预处理函数，可根据需要进行扩展\ndef preprocess_text(text):\n    text = text.lower()\n    text = re.sub(r'[^\\w\\s]', '', text)\n    return text\n\ndef load_data(filepath, input_shape=20):\n    df = pd.read_csv(filepath, encoding='gbk')\n\n    # 文本清理\n    df['evaluation'] = df['evaluation'].apply(preprocess_text)\n\n    # 提取标签和文本（evaluation）\n    labels = df['label'].unique().tolist()\n    vocabulary_list = df['evaluation'].unique().tolist()\n\n    # 构造字符级别词表\n    string = ''\n    for text in vocabulary_list:\n        string += text\n    vocabulary = set(string)\n\n    # 建立映射字典\n    word_dict = {word: i + 1 for i, word in enumerate(vocabulary)}\n    label_dict = {label: i for i, label in enumerate(labels)}\n    output_dict = {i: label for label, i in label_dict.items()}\n    vocab_size = len(word_dict)\n    label_size = len(label_dict)\n\n    # 保存字典\n    with open('word_dict.pk', 'wb') as f:\n        pickle.dump(word_dict, f)\n    with open('label_dict.pk', 'wb') as f:\n        pickle.dump(label_dict, f)\n\n    # 转换文本为索引序列\n    x_data = [[word_dict.get(ch, 0) for ch in text] for text in df['evaluation']]\n    x_data = pad_sequences(x_data, maxlen=input_shape, padding='post', value=0)\n\n    # 转换标签为独热向量\n    y_data = [label_dict[label] for label in df['label']]\n    y_data = tf.one_hot(y_data, depth=label_size).numpy()\n\n    return x_data, y_data, vocab_size, label_size, output_dict\n\ndef load_pretrained_embedding(embedding_path, word_dict, vocab_size, emb_dim=300):\n    \"\"\"\n    读取预训练的词向量，并用其初始化 Embedding 矩阵。\n    这里仅做示例，可根据实际预训练文件格式进行修改。\n    \"\"\"\n    # 初始化 (vocab_size + 1) * emb_dim 的零矩阵\n    embedding_matrix = np.zeros((vocab_size + 1, emb_dim))\n\n    # 假设embedding_path是一个“词\\t向量...”格式的txt文件\n    with open(embedding_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            values = line.strip().split()\n            if len(values) < emb_dim + 1:\n                continue\n            word = values[0]\n            coeffs = np.asarray(values[1:], dtype='float32')\n            index = word_dict.get(word, None)\n            if index is not None and index <= vocab_size:\n                embedding_matrix[index] = coeffs\n    return embedding_matrix\n\ndef create_model(\n    input_shape, vocab_size, label_size, emb_dim=300, n_units=128,\n    pretrained_weights=None\n):\n    \"\"\"\n    使用预训练词向量 + 双向 LSTM + Attention 的模型。\n    pretrained_weights: 如果为 None，则随机初始化，否则加载预训练。\n    \"\"\"\n    # 输入层\n    inputs = tf.keras.Input(shape=(input_shape,), name='input_layer')\n\n    # Embedding 层\n    if pretrained_weights is not None:\n        embedding_layer = Embedding(\n            input_dim=vocab_size + 1,\n            output_dim=emb_dim,\n            weights=[pretrained_weights],\n            input_length=input_shape,\n            trainable=False,  # 初始阶段可设为 False，仅微调可再设为 True\n            mask_zero=True\n        )\n    else:\n        embedding_layer = Embedding(\n            input_dim=vocab_size + 1,\n            output_dim=emb_dim,\n            input_length=input_shape,\n            mask_zero=True\n        )\n\n    x = embedding_layer(inputs)\n    x = Bidirectional(LSTM(n_units, return_sequences=True))(x)\n    x = Dropout(0.5)(x)\n    # 引入 Attention 机制\n    x = AttentionLayer()(x)\n    x = Dropout(0.5)(x)\n    outputs = Dense(label_size, activation='softmax')(x)\n\n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    model.summary()\n    return model\n\ndef train_model(\n    data_path,\n    input_shape=100,\n    embedding_path=None,\n    emb_dim=300,\n    n_units=128,\n    batch_size=64,\n    epochs=50,\n    model_save_path='best_model.h5'\n):\n    \"\"\"\n    训练流程函数\n    \"\"\"\n    x_data, y_data, vocab_size, label_size, output_dict = load_data(data_path, input_shape=input_shape)\n    train_x, test_x, train_y, test_y = train_test_split(x_data, y_data, test_size=0.1, random_state=42)\n\n    # 加载预训练向量\n    pretrained_weights = None\n    if embedding_path and os.path.exists(embedding_path):\n        with open('word_dict.pk', 'rb') as f:\n            word_dict = pickle.load(f)\n        pretrained_weights = load_pretrained_embedding(embedding_path, word_dict, vocab_size, emb_dim=emb_dim)\n\n    model = create_model(\n        input_shape=input_shape,\n        vocab_size=vocab_size,\n        label_size=label_size,\n        emb_dim=emb_dim,\n        n_units=n_units,\n        pretrained_weights=pretrained_weights\n    )\n\n    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    checkpoint = ModelCheckpoint(model_save_path, monitor='val_loss', save_best_only=True)\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5)\n\n    model.fit(\n        train_x, train_y,\n        validation_split=0.1,\n        epochs=epochs,\n        batch_size=batch_size,\n        callbacks=[early_stopping, checkpoint, reduce_lr],\n        verbose=1\n    )\n\n    # 测试\n    y_pred = model.predict(test_x)\n    y_pred_labels = np.argmax(y_pred, axis=1)\n    y_true_labels = np.argmax(test_y, axis=1)\n\n    acc = accuracy_score(y_true_labels, y_pred_labels)\n    print(\"测试集准确率:\", acc)\n\n    return model\n\nif __name__ == '__main__':\n    data_path = '/home/mw/project/datasets.csv'\n    emb_path = 'None'  # 如果暂无预训练词向量文件，可设为 None\n    trained_model = train_model(\n        data_path=data_path,\n        input_shape=180,\n        embedding_path=emb_path,\n        emb_dim=300,\n        n_units=128,\n        batch_size=64,\n        epochs=50,\n        model_save_path='best_model.h5'\n    )","outputs":[{"name":"stderr","output_type":"stream","text":"2025-03-06 11:55:57.371091: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2025-03-06 11:55:57.372641: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-03-06 11:55:57.375978: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-03-06 11:55:57.385064: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1741262157.400799      67 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1741262157.405290      67 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-03-06 11:55:57.421482: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\nMatplotlib created a temporary cache directory at /tmp/matplotlib-l_7rz6a4 because the default path (/home/jovyan/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n2025-03-06 11:56:02.220844: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n/opt/conda/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n/opt/conda/lib/python3.11/site-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'attention_layer' (of type AttentionLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,731,300</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">439,296</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ attention_layer     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)    │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m300\u001b[0m)  │  \u001b[38;5;34m1,731,300\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n","│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n","│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │    \u001b[38;5;34m439,296\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n","│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ attention_layer     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n","│ (\u001b[38;5;33mAttentionLayer\u001b[0m)    │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_layer[\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │        \u001b[38;5;34m514\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,236,902</span> (8.53 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,236,902\u001b[0m (8.53 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,236,902</span> (8.53 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,236,902\u001b[0m (8.53 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["2025-03-06 11:56:06.250908: E tensorflow/core/util/util.cc:131] oneDNN supports DT_BOOL only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"]},{"name":"stdout","output_type":"stream","text":"\u001b[1m1519/1519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9507 - loss: 0.1586"},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":"\u001b[1m1519/1519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1762s\u001b[0m 1s/step - accuracy: 0.9507 - loss: 0.1586 - val_accuracy: 0.9772 - val_loss: 0.0660 - learning_rate: 0.0010\nEpoch 2/50\n\u001b[1m1519/1519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1676s\u001b[0m 1s/step - accuracy: 0.9835 - loss: 0.0397 - val_accuracy: 0.9734 - val_loss: 0.0842 - learning_rate: 5.0000e-04\nEpoch 13/50\n\u001b[1m1519/1519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1693s\u001b[0m 1s/step - accuracy: 0.9843 - loss: 0.0342 - val_accuracy: 0.9754 - val_loss: 0.0902 - learning_rate: 5.0000e-04\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 163ms/step\n测试集准确率: 0.9755833333333334\n"}],"execution_count":2},{"cell_type":"markdown","metadata":{"id":"6543B577A78E45EF8F93A5FA276DC461","jupyter":{},"notebookId":"67ca4cac8fded24f7f8a6580","papermill":{"duration":0.930433,"end_time":"2025-03-06T18:07:08.239877","exception":false,"start_time":"2025-03-06T18:07:07.309444","status":"completed"},"runtime":{"status":"default","execution_status":null,"is_visible":false},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":"测试"},{"cell_type":"code","metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2025-03-06T18:07:10.208609Z","iopub.status.busy":"2025-03-06T18:07:10.207849Z","iopub.status.idle":"2025-03-06T18:07:10.216958Z","shell.execute_reply":"2025-03-06T18:07:10.216506Z"},"id":"EAA5ECDB0EDF4149A00F371D4F80189C","jupyter":{"source_hidden":true},"notebookId":"67ca4cac8fded24f7f8a6580","papermill":{"duration":0.955094,"end_time":"2025-03-06T18:07:10.217894","exception":false,"start_time":"2025-03-06T18:07:09.262800","status":"completed"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"# Import the necessary modules\nimport pickle\nimport numpy as np\nfrom keras.models import load_model\nfrom keras.preprocessing.sequence import pad_sequences\n\n\n# 导入字典\nwith open('word_dict.pk', 'rb') as f:\n    word_dictionary = pickle.load(f)\nwith open('label_dict.pk', 'rb') as f:\n    output_dictionary = pickle.load(f)\n\ntry:\n    # 数据预处理\n    input_shape = 180\n    # 在这里改字，可以自己玩一下，效果不太好\n    sent = \"真不错\"\n    x = [[word_dictionary[word] for word in sent]]\n    x = pad_sequences(maxlen=input_shape, sequences=x, padding='post', value=0)\n\n    # 载入模型\n    model_save_path = '/home/mw/project/corpus_model.h5'\n    lstm_model = load_model(model_save_path)\n\n    # 模型预测\n    y_predict = lstm_model.predict(x)\n    label_dict = {v:k for k,v in output_dictionary.items()}\n    print('输入语句: %s' % sent)\n    print('情感预测结果: %s' % label_dict[np.argmax(y_predict)])\n\nexcept KeyError as err:\n    print(\"您输入的句子有汉字不在词汇表中，请重新输入！\")\n    print(\"不在词汇表中的单词为：%s.\" % err)\n","outputs":[{"output_type":"stream","name":"stderr","text":"WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"},{"output_type":"stream","name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n输入语句: 真不错\n情感预测结果: 积极\n"}],"execution_count":12},{"cell_type":"code","metadata":{"collapsed":false,"id":"86C318EC97A549C184F74B74B8F15543","jupyter":{"source_hidden":true},"notebookId":"67ca4cac8fded24f7f8a6580","papermill":{"duration":1.015781,"end_time":"2025-03-06T18:07:12.164125","exception":false,"start_time":"2025-03-06T18:07:11.148344","status":"completed"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"","outputs":[],"execution_count":null}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"},"papermill":{"default_parameters":{},"duration":22279.158232,"end_time":"2025-03-06T18:07:14.209508","environment_variables":{},"exception":null,"input_path":"s3://kesci-lab-ipynb/67c98d3d98a68553483928f8.ipynb","output_path":"s3://kesci-datasets-uploaded-files/mpijob-outputs/67c98d3d98a68553483928f8/0.ipynb","parameters":{},"start_time":"2025-03-06T11:55:55.051276","version":"2.3.1"}},"nbformat":4,"nbformat_minor":5}
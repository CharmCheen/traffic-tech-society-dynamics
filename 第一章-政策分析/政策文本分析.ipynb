{"cells":[{"cell_type":"code","metadata":{"id":"406FFD0743A14DB2AFA2B23FE1B72D6A","notebookId":"67d92536a91fafc1b329b06a","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"import os\nimport glob\nimport jieba\nimport jieba.posseg as pseg\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\nimport re\n\n# 从多个停用词文件中加载停用词并合并\ndef load_stopwords_from_files(file_paths):\n    stopwords = set()\n    for path in file_paths:\n        if os.path.exists(path):\n            with open(path, 'r', encoding='utf-8') as f:\n                stopwords.update([line.strip() for line in f if line.strip()])\n        else:\n            print(f\"警告: 停用词文件 {path} 不存在\")\n    return stopwords\n\n# 定义停用词文件列表（可根据需要扩展路径）\nSTOPWORDS_FILES = [\n    '/home/mw/project/stopwords/停用词.txt',\n    '/home/mw/project/stopwords/baidu_stopwords.txt',\n    '/home/mw/project/stopwords/cn_stopwords.txt',\n    '/home/mw/project/stopwords/hit_stopwords.txt',\n    '/home/mw/project/stopwords/scu_stopwords.txt'\n]\n\nSTOPWORDS = load_stopwords_from_files(STOPWORDS_FILES)\n\n# 加载指定文件夹下所有txt文档\ndef load_documents(folder_path, encoding='utf-8'):\n    documents = []\n    file_pattern = os.path.join(folder_path, '*.txt')\n    for file_path in glob.glob(file_pattern):\n        with open(file_path, 'r', encoding=encoding) as f:\n            documents.append(f.read())\n    return documents\n\n# 1. 数据清洗与预处理\ndef text_cleaning(text):\n    # 去除特殊符号和标点\n    text = re.sub(r'[^\\u4e00-\\u9fa5a-zA-Z0-9]', ' ', text)\n    # 分词与词性标注\n    words = pseg.cut(text)\n    # 只保留名词、动词、形容词等实词且不在停用词列表中的词\n    filtered_words = [word.word for word in words if word.flag in ['n', 'v', 'a'] and word.word not in STOPWORDS]\n    return ' '.join(filtered_words)\n\n# 2. 主题模型分析（LDA）\ndef lda_analysis(texts, n_topics=5):\n    min_df_val = 1 if len(texts) < 2 else 2\n    tf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=min_df_val, max_features=1000)\n    tf = tf_vectorizer.fit_transform(texts)\n    lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n    lda.fit(tf)\n    feature_names = tf_vectorizer.get_feature_names_out()\n    for topic_idx, topic in enumerate(lda.components_):\n        top_words = [feature_names[i] for i in topic.argsort()[:-11:-1]]\n        print(f\"主题 {topic_idx + 1}: {' '.join(top_words)}\")\n    return lda, tf_vectorizer\n\n# 3. TF-IDF关键词提取（提取更多关键词并保留权重）\ndef tfidf_keywords(texts, top_n=20):\n    tfidf = TfidfVectorizer(max_features=1000)\n    tfidf_matrix = tfidf.fit_transform(texts)\n    feature_names = tfidf.get_feature_names_out()\n    doc_scores = tfidf_matrix[0].toarray().flatten()\n    sorted_indices = np.argsort(doc_scores)[::-1]\n    keywords = [(feature_names[i], doc_scores[i]) for i in sorted_indices[:top_n]]\n    return keywords\n\n# 4. 情感分析（单文档情感分析）\ndef sentiment_analysis(text):\n    analysis = TextBlob(text)\n    return analysis.sentiment.polarity  # 返回情感极性(-1到1)\n\nmask_path = '/home/mw/project/mask/mask_computer.png'\n# 5. 根据 TF-IDF 权重生成词云（指定中文字体解决乱码问题）\ndef generate_wordcloud_from_frequencies(frequencies, output_path='future_industry_wordcloud.png', mask_path=None, width=800, height=600):\n    if mask_path:\n        mask = np.array(Image.open(mask_path))\n    else:\n        mask = None\n    wc = WordCloud(\n        background_color='white',\n        max_words=500,\n        contour_width=3,\n        contour_color='steelblue',\n        font_path='/home/mw/project/font/仿宋_GB2312.ttf',  # 请确保该字体文件存在或使用绝对路径\n        width=width,\n        height=height,\n        mask=mask\n    )\n    wc.generate_from_frequencies(frequencies)\n    plt.figure(figsize=(12, 8))\n    plt.imshow(wc, interpolation='bilinear')\n    plt.axis('off')\n    plt.show()\n    wc.to_file(output_path)\n\nif __name__ == \"__main__\":\n    # 加载多个文档，替换为实际存放txt文件的文件夹路径\n    folder_path = '/home/mw/project/document'\n    docs = load_documents(folder_path)\n    print(f\"共加载 {len(docs)} 个文档\")\n\n    # 对每个文档进行清洗\n    cleaned_docs = [text_cleaning(doc) for doc in docs]\n\n    # 主题模型分析：传入多个文档\n    lda, tf_vectorizer = lda_analysis(cleaned_docs)\n\n    # TF-IDF关键词提取（此处以第一个文档为示例）\n    keywords = tfidf_keywords(cleaned_docs)\n    print(\"\\nTF-IDF关键词及权重：\")\n    for kw, score in keywords:\n        print(f\"{kw}: {score:.4f}\")\n\n    # 情感分析（仅对第一个文档）\n    polarity = sentiment_analysis(cleaned_docs[0])\n    print(f\"\\n第1个文档情感极性: {polarity}\")\n\n    # 构造综合的TF-IDF权重词典（合并多个文档）\n    tfidf = TfidfVectorizer(max_features=1000)\n    tfidf_matrix = tfidf.fit_transform(cleaned_docs)\n    feature_names = tfidf.get_feature_names_out()\n    weights = np.sum(tfidf_matrix.toarray(), axis=0)\n    freq_dict = {feature_names[i]: weights[i] for i in range(len(feature_names))}\n    generate_wordcloud_from_frequencies(freq_dict)","outputs":[{"output_type":"stream","name":"stderr","text":"Building prefix dict from the default dictionary ...\nLoading model from cache /tmp/jieba.cache\n"},{"output_type":"stream","name":"stdout","text":"共加载 5 个文档\n"},{"output_type":"stream","name":"stderr","text":"Loading model cost 0.792 seconds.\nPrefix dict has been built successfully.\n"},{"output_type":"stream","name":"stdout","text":"主题 1: 提供 应对 远程 模式 社会 增加 用于 医疗 方向 关系\n主题 2: 创新 产业 交通 装备 领域 体系 构建 提升 强化 基础\n主题 3: 科学技术 文化 社会 方式 结构 人工智能 创新 深远 传统 效率\n主题 4: 道路 车辆 示范 驾驶 相关 汽车 主管部门 政府 行驶 智能网\n主题 5: 提供 应对 远程 模式 社会 增加 用于 医疗 方向 关系\n\nTF-IDF关键词及权重：\n产业: 0.4975\n创新: 0.2019\n技术: 0.1951\n企业: 0.1714\n加快: 0.1646\n场景: 0.1514\n产品: 0.1457\n装备: 0.1371\n领域: 0.1298\n重点: 0.1286\n打造: 0.1286\n智能: 0.1281\n量子: 0.1280\n推广: 0.1136\n构建: 0.1114\n推动: 0.1098\n标准: 0.1081\n推进: 0.1028\n制造: 0.1009\n体系: 0.0943\n\n第1个文档情感极性: 0.0\n"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x800 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/406FFD0743A14DB2AFA2B23FE1B72D6A/std0s1a2w6.png\">"},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","metadata":{"id":"97273B9689704082846E287B17C49989","notebookId":"67d92536a91fafc1b329b06a","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"一、紧扣 “创新驱动发展战略”，强化核心技术突破  \n创新主体明确：TF-IDF 中 “企业”（0.1714）权重突出，体现企业作为创新主体的地位，契合国家 “强化企业创新主体地位” 的战略部署。词云高频词 “创新”“技术” 直接呼应创新驱动发展战略，表明通过技术创新推动产业升级是核心方向。  \n前沿技术布局：“量子”“人工智能” 等词反映对前沿科技的关注，与国家 “瞄准量子信息、人工智能等战略性新兴产业” 的布局一致，通过突破关键核心技术，夯实创新驱动的科技基础。  \n二、对接 “制造强国” 战略，推动产业高端化发展  \n产业体系构建：主题 2 中 “产业”“装备”“制造”“体系”“构建” 等词，结合 TF-IDF 里 “产业”（0.4975）、“装备”（0.1371）等关键词，体现对高端装备制造、现代化产业体系建设的重视，契合制造强国战略中 “推动制造业高端化、智能化、绿色化发展” 的要求。  \n新质生产力培育：词云 “智能”“技术” 与 “制造” 的关联，以及 TF-IDF 中 “智能”（0.1281）“推动”（0.1098）等词，指向以技术创新赋能制造业，通过智能化改造、技术转化应用，培育 “以科技创新为核心驱动力” 的新质生产力，实现从传统制造向先进制造的跃升。  \n三、践行新发展理念，以创新引领协调发展  \n创新理念贯穿全程：“创新” 一词在词云、主题、TF-IDF 中高频出现（如 “创新” TF-IDF 权重 0.2019），深度落实新发展理念中 “创新是引领发展的第一动力” 的要求，通过技术创新、产业创新打破传统发展路径依赖。  \n产业协同发展导向：主题 2 中 “领域”“提升”“强化”“基础” 等词，体现产业发展中注重基础能力建设与多领域协同，呼应新发展理念中 “协调” 内涵，推动产业链上下游、科技与产业间的协调发展，构建更具竞争力的产业生态。  \n四、锚定新质生产力，推动科技 - 产业深度融合  \n科技成果转化应用：TF-IDF 中 “推广”（0.1136）“标准”（0.1081）等词，表明注重将 “量子”“人工智能” 等科技成果转化为产业标准与应用场景，符合新质生产力 “推动科技成果向现实生产力转化” 的要求。  \n场景驱动产业升级：词云隐含的 “应用”“场景”（TF-IDF 中 “场景” 0.1514），指向通过智能网联汽车、医疗等应用场景拓展，加速技术落地，以场景驱动产业变革，培育经济发展新动能，正是新质生产力 “以新产业、新业态、新模式重塑经济结构” 的实践体现。"},{"cell_type":"code","metadata":{"id":"E87DD163124A411F8C26442176A3BAAB","notebookId":"67d92536a91fafc1b329b06a","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"import networkx as nx\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\n\n# 注册自定义字体\nfont_path = \"/home/mw/project/font/仿宋_GB2312.ttf\"\nfont_prop = fm.FontProperties(fname=font_path)\nplt.rcParams['font.family'] = font_prop.get_name()\n\n# 假设已经有了 TF-IDF 矩阵和特征名称\n# tfidf_matrix 和 feature_names 是之前代码中已经计算得到的\n\n# 1. 构建共现矩阵\nco_occurrence_matrix = (tfidf_matrix.T * tfidf_matrix)\nco_occurrence_matrix.setdiag(0)  # 将对角线元素置为 0，排除自身共现\n\n# 2. 创建网络\nG = nx.Graph()\nfor i in range(len(feature_names)):\n    for j in range(i + 1, len(feature_names)):\n        if co_occurrence_matrix[i, j] > 0:\n            G.add_edge(feature_names[i], feature_names[j], weight=co_occurrence_matrix[i, j])\n\n# 3. 分析网络拓扑结构\n# 计算节点度\ndegree = dict(G.degree(weight='weight'))\n# 计算度中心性\ndegree_centrality = nx.degree_centrality(G)\n# 计算介数中心性\nbetweenness_centrality = nx.betweenness_centrality(G)\n\n# 输出前 10 个度中心性最高的关键词\nprint(\"度中心性最高的前 10 个关键词：\")\nsorted_degree_centrality = sorted(degree_centrality.items(), key=lambda item: item[1], reverse=True)[:10]\nfor keyword, centrality in sorted_degree_centrality:\n    print(f\"{keyword}: {centrality:.4f}\")\n\n# 输出前 10 个介数中心性最高的关键词\nprint(\"\\n介数中心性最高的前 10 个关键词：\")\nsorted_betweenness_centrality = sorted(betweenness_centrality.items(), key=lambda item: item[1], reverse=True)[:10]\nfor keyword, centrality in sorted_betweenness_centrality:\n    print(f\"{keyword}: {centrality:.4f}\")\n\n# 4. 可视化网络\nplt.figure(figsize=(12, 8))\npos = nx.spring_layout(G)\nnx.draw_networkx_nodes(G, pos, node_size=[v * 1000 for v in degree.values()], node_color='lightblue')\nnx.draw_networkx_edges(G, pos, edge_color='gray', alpha=0.5)\n# 此处直接调用，不传入 font_properties 参数，使用全局字体设置即可\nnx.draw_networkx_labels(G, pos, font_size=10)\nedge_labels = {(u, v): d['weight'] for u, v, d in G.edges(data=True)}\nnx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\nplt.title('关键词共现网络')\nplt.axis('off')\nplt.show()\n","outputs":[{"output_type":"stream","name":"stdout","text":"度中心性最高的前 10 个关键词：\n信息: 1.0000\n先进: 1.0000\n加快: 1.0000\n国家: 1.0000\n技术: 1.0000\n控制: 1.0000\n推动: 1.0000\n支持: 1.0000\n数据: 1.0000\n智能: 1.0000\n\n介数中心性最高的前 10 个关键词：\n信息: 0.0042\n先进: 0.0042\n加快: 0.0042\n国家: 0.0042\n技术: 0.0042\n控制: 0.0042\n推动: 0.0042\n支持: 0.0042\n数据: 0.0042\n智能: 0.0042\n"},{"output_type":"stream","name":"stderr","text":"findfont: Font family 'FangSong_GB2312' not found.\nfindfont: Font family 'FangSong_GB2312' not found.\n/opt/conda/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 20851 (\\N{CJK UNIFIED IDEOGRAPH-5173}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 38190 (\\N{CJK UNIFIED IDEOGRAPH-952E}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 35789 (\\N{CJK UNIFIED IDEOGRAPH-8BCD}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 20849 (\\N{CJK UNIFIED IDEOGRAPH-5171}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 29616 (\\N{CJK UNIFIED IDEOGRAPH-73B0}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 32593 (\\N{CJK UNIFIED IDEOGRAPH-7F51}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 32476 (\\N{CJK UNIFIED IDEOGRAPH-7EDC}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\nfindfont: Font family 'FangSong_GB2312' not found.\nfindfont: Font family 'FangSong_GB2312' not found.\nfindfont: Font family 'FangSong_GB2312' not found.\nfindfont: Font family 'FangSong_GB2312' not found.\nfindfont: Font family 'FangSong_GB2312' not found.\nfindfont: Font family 'FangSong_GB2312' not found.\nfindfont: Font family 'FangSong_GB2312' not found.\n"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x800 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/E87DD163124A411F8C26442176A3BAAB/std1ds59mc.png\">"},"metadata":{}}],"execution_count":2},{"cell_type":"code","metadata":{"id":"310F5F1725FB47EAB53F900A1BDCE7CE","notebookId":"67d92536a91fafc1b329b06a","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"import networkx as nx\nimport matplotlib.pyplot as plt\n\n# 注册自定义字体\nfont_path = \"/home/mw/project/font/仿宋_GB2312.ttf\"\nfont_prop = fm.FontProperties(fname=font_path)\nplt.rcParams['font.family'] = font_prop.get_name()\n\n# 假设已构建好 G、pos 等网络元素\nplt.figure(figsize=(14, 10))\n\n# 查询并设置正确字体名称（假设识别名称为 'FangSong'）\nplt.rcParams['font.family'] = 'FangSong'\n\nnx.draw_networkx_nodes(G, pos, node_size=[v * 2000 for v in degree.values()], node_color='lightblue')\nnx.draw_networkx_edges(G, pos, edge_color='gray', alpha=0.5)\nnx.draw_networkx_labels(G, pos, font_size=12, font_weight='bold')\nedge_labels = {(u, v): d['weight'] for u, v, d in G.edges(data=True)}\nnx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=10)\nplt.title('关键词共现网络', fontsize=16, fontweight='bold')\nplt.axis('off')\nplt.show()","outputs":[{"output_type":"stream","name":"stderr","text":"findfont: Font family 'FangSong' not found.\nfindfont: Font family 'FangSong' not found.\n/opt/conda/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 20851 (\\N{CJK UNIFIED IDEOGRAPH-5173}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 38190 (\\N{CJK UNIFIED IDEOGRAPH-952E}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 35789 (\\N{CJK UNIFIED IDEOGRAPH-8BCD}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 20849 (\\N{CJK UNIFIED IDEOGRAPH-5171}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 29616 (\\N{CJK UNIFIED IDEOGRAPH-73B0}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 32593 (\\N{CJK UNIFIED IDEOGRAPH-7F51}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/opt/conda/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 32476 (\\N{CJK UNIFIED IDEOGRAPH-7EDC}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\nfindfont: Font family 'FangSong' not found.\nfindfont: Font family 'FangSong' not found.\nfindfont: Font family 'FangSong' not found.\nfindfont: Font family 'FangSong' not found.\nfindfont: Font family 'FangSong' not found.\nfindfont: Font family 'FangSong' not found.\nfindfont: Font family 'FangSong' not found.\n"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1400x1000 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/310F5F1725FB47EAB53F900A1BDCE7CE/std37zorjs.png\">"},"metadata":{}}],"execution_count":7}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}